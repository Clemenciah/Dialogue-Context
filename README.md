# Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems, accepted at NAACL'24
The repository consists of data used for analysis to understand how different context sizes and types influence the consistency of human evaluation labels.
